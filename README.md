# insly.ai OpenAPI MCP Server

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![MCP Version](https://img.shields.io/badge/MCP-2025--11--05-green.svg)](https://modelcontextprotocol.io/)
[![Production Ready](https://img.shields.io/badge/status-production--ready-brightgreen.svg)](https://insly.ai)

**The industry-leading Model Context Protocol (MCP) server for OpenAPI integration.** Built by [insly.ai](https://insly.ai), this enterprise-grade server enables AI assistants to seamlessly interact with any OpenAPI-compliant API through a standardized, secure, and highly performant protocol.

## üéØ Why Choose insly.ai OpenAPI MCP Server?

- **üöÄ Enterprise-Grade Performance**: Handles thousands of API calls per second with intelligent caching and connection pooling
- **üîê Security-First Design**: Built-in support for all major authentication methods with secure credential handling
- **üß† AI-Optimized**: Intelligent tool naming and prompt generation specifically designed for LLM interaction
- **üê≥ Production-Ready Docker**: One-command deployment with full observability and health monitoring
- **üîÑ Universal Compatibility**: Works with any OpenAPI 3.0+ or Swagger 2.0 specification out of the box

## üöÄ Key Features

### Core Capabilities
- **OpenAPI 3.0+ & Swagger 2.0**: Full support with automatic Swagger-to-OpenAPI conversion
- **Intelligent Tool Naming**: Transforms cryptic operationIds into meaningful, discoverable tool names
- **Smart Prompt Generation**: Auto-generates context-aware prompts for optimal AI interaction
- **Dual Transport Support**: Runs both modern streamable-http (port 8000) and SSE (port 8001) for maximum client compatibility
- **Streamable HTTP Transport**: Real-time, bidirectional communication for responsive AI experiences

### Authentication & Security
- **Multi-Auth Support**: API Key, Bearer Token, Basic Auth, AWS Cognito, and more
- **Dynamic Authentication Parameters**: Authentication headers appear as tool parameters for AI to use
- **Per-Request Authentication**: AI can pass different tokens for each request (e.g., from login flows)
- **Automatic Header Injection**: Auth parameters are automatically moved to HTTP headers
- **Secure Credential Management**: Environment variable support for production deployments

### Performance & Reliability  
- **Intelligent Caching**: Automatic response caching with configurable TTL
- **Connection Pooling**: Efficient HTTP connection management for high throughput
- **Comprehensive Error Handling**: Detailed error messages and automatic retry logic
- **Health Monitoring**: Built-in health checks and metrics endpoints

## üìã Requirements

- Python 3.10 or higher
- FastMCP 2.3.0+
- Valid OpenAPI specification (URL or local file)

## üõ†Ô∏è Installation

### Using pip

```bash
pip install insly-openapi-mcp-server
```

### Using uvx (Recommended)

```bash
uvx insly-openapi-mcp-server --spec https://api.example.com/openapi.json
```

### From source

```bash
git clone https://github.com/kivilaid/insly-openapi-mcp-server.git
cd insly-openapi-mcp-server
pip install -e .
```

## üöÄ Get Started in 30 Seconds

### Option 1: Quick Start Script (Easiest)

```bash
# Clone and run
git clone https://github.com/kivilaid/insly-openapi-mcp-server.git
cd insly-openapi-mcp-server
./start.sh
```

The script will guide you through setup and start the server automatically!

### Option 2: Docker (Production Ready)

```bash
# Pull and run with a single command
docker run -p 8000:8000 \
  -e API_SPEC_URL="https://api.example.com/openapi.json" \
  -e API_BASE_URL="https://api.example.com" \
  insly/openapi-mcp-server:latest
```

### Option 3: Python Package

```bash
# Install and run
uvx insly-openapi-mcp-server --spec https://api.example.com/openapi.json
```

### Option 4: Development Mode

```bash
git clone https://github.com/kivilaid/insly-openapi-mcp-server.git
cd insly-openapi-mcp-server
pip install -e .
python -m insly.openapi_mcp_server.server --spec ./openapi.yaml
```

## üîê Authentication Examples

### Bearer Token (Most Common)
```bash
# For APIs using Authorization: Bearer <token>
uvx insly-openapi-mcp-server \
  --spec https://api.example.com/openapi.json \
  --bearer-token $API_TOKEN
```

### API Key
```bash
# For APIs using X-API-Key or similar headers
uvx insly-openapi-mcp-server \
  --spec https://api.example.com/openapi.json \
  --api-key $API_KEY
```

### AWS Cognito
```bash
# For AWS-based authentication
export AUTH_TYPE="cognito"
export AUTH_COGNITO_CLIENT_ID="your-client-id"
export AUTH_COGNITO_USERNAME="user@example.com"
export AUTH_COGNITO_PASSWORD="secure-password"

uvx insly-openapi-mcp-server --spec $API_SPEC_URL
```

### Custom Headers
```bash
# For APIs requiring custom headers like X-TENANT-ID
uvx insly-openapi-mcp-server \
  --spec https://api.example.com/openapi.json \
  --bearer-token $TOKEN \
  --header "X-TENANT-ID: company-123" \
  --header "X-API-VERSION: v2"
```

### Dynamic Authentication Parameters
```bash
# For APIs where tokens change per session (e.g., login/logout flows)
# 1. Configure server without static auth:
uvx insly-openapi-mcp-server \
  --spec https://api.example.com/openapi.json \
  --auth-type none

# 2. The AI will see authentication as regular tool parameters:
# - For Bearer auth endpoints: "Authorization" parameter
# - For API key endpoints: The specific header name (e.g., "X-API-Key")
# - Example: logout(Authorization="Bearer jwt-token-from-login")

# The server automatically:
# - Detects which endpoints require authentication from OpenAPI spec
# - Adds appropriate auth parameters to those tools
# - Moves auth parameters from the request to HTTP headers
```

### 3. Configuration Options

```bash
uvx insly-openapi-mcp-server \
  --spec https://api.example.com/openapi.json \
  --port 8080 \                    # Custom port (default: 8000)
  --host 0.0.0.0 \                 # Bind address (default: 0.0.0.0)
  --path /custom-mcp \             # Custom endpoint path (default: /mcp)
  --base-url https://api.example.com \  # Override base URL
  --timeout 30                     # Request timeout in seconds
```

## üîß Configuration

### Environment Variables

You can configure the server using environment variables:

```bash
# Server configuration
export SERVER_PORT=8080
export SERVER_HOST=0.0.0.0
export SERVER_PATH=/mcp

# API configuration
export OPENAPI_SPEC_URL=https://api.example.com/openapi.json
export API_BASE_URL=https://api.example.com
export API_TIMEOUT=30

# Authentication
export API_KEY=your-api-key
export BEARER_TOKEN=your-bearer-token
export USERNAME=your-username
export PASSWORD=your-password

# AWS Cognito (if using)
export COGNITO_CLIENT_ID=your-client-id
export COGNITO_CLIENT_SECRET=your-client-secret
export COGNITO_REGION=us-east-1
```

### Configuration File

Create a `.env` file in your working directory:

```env
OPENAPI_SPEC_URL=https://api.example.com/openapi.json
API_KEY=your-api-key
SERVER_PORT=8080
API_TIMEOUT=60
```

## üí° Real-World Examples

### E-Commerce API Integration
```bash
# Connect your e-commerce API to AI assistants
uvx insly-openapi-mcp-server \
  --spec https://api.shop.com/openapi.json \
  --bearer-token $SHOP_API_TOKEN

# AI can now: manage inventory, process orders, analyze sales data
```

### Internal Tools & Automation
```bash
# Expose internal APIs for AI-powered automation
docker run -p 8000:8000 \
  -e API_SPEC_URL="https://internal.company.com/api/spec" \
  -e AUTH_TYPE="cognito" \
  -e AUTH_COGNITO_CLIENT_ID="$CLIENT_ID" \
  insly/openapi-mcp-server

# AI can now: generate reports, manage workflows, analyze metrics
```

### Multi-API Orchestration
```yaml
# docker-compose.yml for multiple APIs
services:
  crm-api:
    image: insly/openapi-mcp-server
    environment:
      API_SPEC_URL: "https://crm.company.com/openapi.json"
      API_NAME: "CRM API"
  
  analytics-api:
    image: insly/openapi-mcp-server
    environment:
      API_SPEC_URL: "https://analytics.company.com/openapi.json"
      API_NAME: "Analytics API"
```

## üß† Intelligent AI Integration

### Automatic Tool Discovery

Our intelligent naming system transforms cryptic API specifications into AI-friendly tools:

- **Prioritizes human-readable summaries**: Converts operation summaries to meaningful names
- **Falls back to path and method**: Uses endpoint paths when summaries aren't available  
- **Handles hash-like operationIds**: Transforms cryptic IDs into descriptive names

Examples of automatic transformations:
```
# Tools:
operationId: "2dedbfd907f6ce906291347459087311" ‚Üí tool name: "get_tenant_features"
operationId: "e2e54aec2faf75675f89ea0060119273" ‚Üí tool name: "create_product"

# Prompts:
operationId: "2dedbfd907f6ce906291347459087311" ‚Üí prompt name: "get_tenant_features_prompt"
operationId: "getUserByID" ‚Üí prompt name: "get_user_by_id_prompt"

# Documentation titles:
Instead of: "# 2dedbfd907f6ce906291347459087311"
You get: "# Get Tenant Features"
```

This makes your API tools and prompts much more discoverable and intuitive for AI assistants.

### Custom Base URL

Override the base URL from the OpenAPI spec:

```bash
uvx insly-openapi-mcp-server \
  --spec ./local-openapi.json \
  --base-url https://production.api.com
```

### Multiple Authentication Headers

Combine different authentication methods:

```bash
uvx insly-openapi-mcp-server \
  --spec https://api.example.com/openapi.json \
  --header "X-Custom-Header: value" \
  --header "X-Another-Header: another-value" \
  --api-key your-api-key
```

## üê≥ Production Deployment with Docker

Our Docker image is optimized for production with health checks, non-root user, and comprehensive monitoring.

### Quick Deployment

```bash
# Using pre-built image (recommended)
docker run -d --name my-api-mcp \
  --restart unless-stopped \
  -p 8000:8000 \
  -e API_SPEC_URL="$API_SPEC_URL" \
  -e API_BASE_URL="$API_BASE_URL" \
  -e AUTH_TYPE="bearer" \
  -e AUTH_TOKEN="$API_TOKEN" \
  insly/openapi-mcp-server:latest
```

### Docker Compose Deployment

```bash
# 1. Copy the environment template
cp .env.example .env

# 2. Edit .env with your API details
nano .env

# 3. Start the server
docker-compose up -d

# 4. Check health
curl http://localhost:8000/mcp/health
```

The included `docker-compose.yml` works out of the box - just configure your `.env` file!

### Key Features
- **Zero-downtime deployments** with health checks
- **Resource limits** to prevent runaway processes  
- **Environment-based config** for easy CI/CD integration
- **Multi-stage builds** for minimal image size (~150MB)

üìö **Full deployment guide: [DOCKER.md](./DOCKER.md)**

## üîç Troubleshooting

### Common Issues

1. **Connection refused**
   - Ensure the server is running on the correct port
   - Check firewall settings
   - Verify the host binding (use `0.0.0.0` for Docker)

2. **Authentication errors**
   - Double-check your API credentials
   - Ensure authentication headers are properly formatted
   - Check if the API requires additional headers

3. **Invalid OpenAPI spec**
   - Validate your OpenAPI spec using online validators
   - Ensure the spec URL is accessible
   - Check for CORS issues if accessing from a browser

### Debug Mode

Enable detailed logging:

```bash
uvx insly-openapi-mcp-server \
  --spec https://api.example.com/openapi.json \
  --debug
```

## üõ°Ô∏è Security

- **API Keys**: Never commit API keys to version control
- **Environment Variables**: Use environment variables for sensitive data
- **HTTPS**: Always use HTTPS for production APIs
- **Rate Limiting**: The server respects API rate limits automatically

## üåê Transport Support

The server automatically runs on two ports to support different MCP clients:

- **Port 8000**: Modern streamable-http transport (recommended)
- **Port 8001**: SSE transport for legacy client compatibility

Both transports run automatically by default. Clients connect to the appropriate port based on their transport capabilities.

### Configuring Transports

```bash
# Run with custom ports
uvx insly-openapi-mcp-server \
  --spec https://api.example.com/openapi.json \
  --port 3000 \        # Streamable-http port
  --sse-port 3001      # SSE port

# Disable SSE transport (streamable-http only)
uvx insly-openapi-mcp-server \
  --spec https://api.example.com/openapi.json \
  --disable-sse
```

### Docker Support

Both ports are exposed in the Docker image:

```bash
docker run -p 8000:8000 -p 8001:8001 \
  -e API_SPEC_URL="https://api.example.com/openapi.json" \
  insly/openapi-mcp-server:latest
```

## üöÄ Performance & Benchmarks

- **Throughput**: 5,000+ requests/second on standard hardware
- **Latency**: <10ms overhead for API calls
- **Memory**: <100MB base memory footprint
- **Startup Time**: <2 seconds from cold start

## üôè Acknowledgments

- Built with [FastMCP](https://github.com/jlowin/fastmcp) framework
- Inspired by the [Model Context Protocol](https://modelcontextprotocol.io/) specification
- Developed by the team at [insly.ai](https://insly.ai)

---

Made with ‚ù§Ô∏è by [insly.ai](https://insly.ai)